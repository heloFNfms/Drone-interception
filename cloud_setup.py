#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº‘ç«¯GPUç¯å¢ƒå¿«é€Ÿé…ç½®è„šæœ¬
ä¸“ä¸ºäº‘ç«¯GPUå®ä¾‹ï¼ˆå¦‚é˜¿é‡Œäº‘ã€è…¾è®¯äº‘ã€AWSç­‰ï¼‰ä¼˜åŒ–
"""

import subprocess
import sys
import os
import time

def run_command(command, timeout=300):
    """æ‰§è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=timeout)
        return result.returncode == 0, result.stdout, result.stderr
    except subprocess.TimeoutExpired:
        return False, "", "å‘½ä»¤æ‰§è¡Œè¶…æ—¶"
    except Exception as e:
        return False, "", str(e)

def check_gpu_environment():
    """æ£€æŸ¥GPUç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥GPUç¯å¢ƒ...")
    
    # æ£€æŸ¥nvidia-smi
    success, stdout, stderr = run_command("nvidia-smi")
    if not success:
        print("âŒ æœªæ£€æµ‹åˆ°NVIDIA GPUæˆ–é©±åŠ¨æœªå®‰è£…")
        print("è¯·ç¡®ä¿æ‚¨é€‰æ‹©çš„æ˜¯GPUå®ä¾‹")
        return False
    
    print("âœ… GPUé©±åŠ¨æ£€æµ‹æˆåŠŸ")
    
    # è§£æGPUä¿¡æ¯
    lines = stdout.split('\n')
    for line in lines:
        if "CUDA Version" in line:
            cuda_version = line.split("CUDA Version: ")[1].split()[0]
            print(f"ğŸ“‹ CUDAç‰ˆæœ¬: {cuda_version}")
            break
    
    # è·å–GPUè¯¦ç»†ä¿¡æ¯
    success, stdout, stderr = run_command("nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv,noheader,nounits")
    if success:
        gpu_info = stdout.strip().split(', ')
        if len(gpu_info) >= 3:
            print(f"ğŸ® GPUå‹å·: {gpu_info[0]}")
            print(f"ğŸ’¾ æ˜¾å­˜å¤§å°: {int(gpu_info[1])/1024:.1f} GB")
            print(f"ğŸ”§ é©±åŠ¨ç‰ˆæœ¬: {gpu_info[2]}")
    
    return True

def install_dependencies():
    """å®‰è£…ä¾èµ–åŒ…"""
    print("\nğŸ“¦ å®‰è£…ä¾èµ–åŒ…...")
    
    # æ›´æ–°pip
    print("æ›´æ–°pip...")
    run_command(f"{sys.executable} -m pip install --upgrade pip")
    
    # åŸºç¡€ä¾èµ–åŒ…
    base_packages = [
        "numpy",
        "scipy", 
        "matplotlib",
        "typing-extensions"
    ]
    
    # ä½¿ç”¨æ¸…åé•œåƒæºæ‰¹é‡å®‰è£…
    package_list = " ".join(base_packages)
    print(f"å®‰è£…åŸºç¡€åŒ…: {package_list}")
    
    success, stdout, stderr = run_command(
        f"{sys.executable} -m pip install {package_list} -i https://pypi.tuna.tsinghua.edu.cn/simple/ --timeout 120"
    )
    
    if success:
        print("âœ… åŸºç¡€ä¾èµ–åŒ…å®‰è£…æˆåŠŸ")
    else:
        print("âš ï¸ åŸºç¡€åŒ…å®‰è£…å¤±è´¥ï¼Œå°è¯•é€ä¸ªå®‰è£…...")
        for package in base_packages:
            success, _, _ = run_command(f"{sys.executable} -m pip install {package}")
            if success:
                print(f"âœ… {package} å®‰è£…æˆåŠŸ")
            else:
                print(f"âŒ {package} å®‰è£…å¤±è´¥")

def install_cupy():
    """å®‰è£…CuPy GPUåŠ é€Ÿåº“"""
    print("\nğŸš€ å®‰è£…CuPy GPUåŠ é€Ÿåº“...")
    
    # æ£€æµ‹CUDAç‰ˆæœ¬
    success, stdout, stderr = run_command("nvidia-smi")
    if success and "CUDA Version" in stdout:
        for line in stdout.split('\n'):
            if "CUDA Version" in line:
                cuda_version = line.split("CUDA Version: ")[1].split()[0]
                major_version = int(cuda_version.split('.')[0])
                break
    else:
        print("âš ï¸ æ— æ³•æ£€æµ‹CUDAç‰ˆæœ¬ï¼Œé»˜è®¤ä½¿ç”¨CUDA 12.x")
        major_version = 12
    
    # é€‰æ‹©åˆé€‚çš„CuPyç‰ˆæœ¬
    if major_version >= 12:
        cupy_package = "cupy-cuda12x"
    elif major_version >= 11:
        cupy_package = "cupy-cuda11x"
    else:
        cupy_package = "cupy-cuda110"
    
    print(f"å®‰è£… {cupy_package}...")
    
    # å°è¯•å¤šä¸ªé•œåƒæº
    mirrors = [
        "https://pypi.tuna.tsinghua.edu.cn/simple/",
        "https://mirrors.aliyun.com/pypi/simple/",
        "https://pypi.douban.com/simple/"
    ]
    
    for mirror in mirrors:
        print(f"å°è¯•é•œåƒæº: {mirror}")
        success, stdout, stderr = run_command(
            f"{sys.executable} -m pip install {cupy_package} -i {mirror} --timeout 300",
            timeout=400
        )
        
        if success:
            print(f"âœ… {cupy_package} å®‰è£…æˆåŠŸ")
            return True
        else:
            print(f"âŒ å®‰è£…å¤±è´¥: {stderr[:200]}...")
    
    # æœ€åå°è¯•å®˜æ–¹æº
    print("å°è¯•å®˜æ–¹PyPIæº...")
    success, stdout, stderr = run_command(
        f"{sys.executable} -m pip install {cupy_package} --timeout 300",
        timeout=400
    )
    
    if success:
        print(f"âœ… {cupy_package} å®‰è£…æˆåŠŸ")
        return True
    else:
        print(f"âŒ CuPyå®‰è£…å¤±è´¥: {stderr}")
        return False

def test_gpu_performance():
    """æµ‹è¯•GPUæ€§èƒ½"""
    print("\nğŸ§ª æµ‹è¯•GPUæ€§èƒ½...")
    
    test_script = '''
import time
import numpy as np

try:
    import cupy as cp
    
    print(f"CuPyç‰ˆæœ¬: {cp.__version__}")
    
    # GPUä¿¡æ¯
    device = cp.cuda.Device()
    with device:
        props = cp.cuda.runtime.getDeviceProperties(device.id)
        print(f"GPU: {props["name"].decode()}")
        
        mem_info = cp.cuda.runtime.memGetInfo()
        total_mem = mem_info[1] / 1024**3
        free_mem = mem_info[0] / 1024**3
        print(f"æ˜¾å­˜: {total_mem:.1f}GB æ€»è®¡, {free_mem:.1f}GB å¯ç”¨")
    
    # æ€§èƒ½åŸºå‡†æµ‹è¯•
    print("\næ‰§è¡ŒçŸ©é˜µä¹˜æ³•åŸºå‡†æµ‹è¯•...")
    sizes = [1000, 2000, 4000]
    
    for size in sizes:
        print(f"\næµ‹è¯•çŸ©é˜µå¤§å°: {size}x{size}")
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        np.random.seed(42)
        a = np.random.random((size, size)).astype(np.float32)
        b = np.random.random((size, size)).astype(np.float32)
        
        # CPUæµ‹è¯•
        start = time.time()
        cpu_result = np.dot(a, b)
        cpu_time = time.time() - start
        
        # GPUæµ‹è¯•
        a_gpu = cp.asarray(a)
        b_gpu = cp.asarray(b)
        cp.cuda.Stream.null.synchronize()
        
        start = time.time()
        gpu_result = cp.dot(a_gpu, b_gpu)
        cp.cuda.Stream.null.synchronize()
        gpu_time = time.time() - start
        
        # éªŒè¯ç»“æœ
        gpu_result_cpu = cp.asnumpy(gpu_result)
        max_diff = np.max(np.abs(cpu_result - gpu_result_cpu))
        
        speedup = cpu_time / gpu_time
        print(f"CPUæ—¶é—´: {cpu_time:.3f}s")
        print(f"GPUæ—¶é—´: {gpu_time:.3f}s")
        print(f"åŠ é€Ÿæ¯”: {speedup:.1f}x")
        print(f"ç²¾åº¦è¯¯å·®: {max_diff:.2e}")
        
        if size == 4000 and speedup > 5:
            print("ğŸ‰ GPUæ€§èƒ½ä¼˜ç§€ï¼Œé€‚åˆå¤§è§„æ¨¡è®¡ç®—")
        elif speedup > 2:
            print("âœ… GPUæ€§èƒ½è‰¯å¥½")
        else:
            print("âš ï¸ GPUåŠ é€Ÿæ•ˆæœæœ‰é™")
    
    print("\nâœ… GPUæ€§èƒ½æµ‹è¯•å®Œæˆ")
    
except ImportError:
    print("âŒ CuPyæœªæ­£ç¡®å®‰è£…")
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
'''
    
    # å°†æµ‹è¯•è„šæœ¬å†™å…¥ä¸´æ—¶æ–‡ä»¶
    with open('gpu_test.py', 'w', encoding='utf-8') as f:
        f.write(test_script)
    
    # æ‰§è¡Œæµ‹è¯•
    success, stdout, stderr = run_command(f"{sys.executable} gpu_test.py", timeout=120)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    try:
        os.remove('gpu_test.py')
    except:
        pass
    
    if success:
        print(stdout)
    else:
        print(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {stderr}")
    
    return success

def setup_optimization_environment():
    """è®¾ç½®ä¼˜åŒ–ç®—æ³•ç¯å¢ƒ"""
    print("\nâš™ï¸ é…ç½®ä¼˜åŒ–ç®—æ³•ç¯å¢ƒ...")
    
    # æ£€æŸ¥ä¼˜åŒ–è„šæœ¬æ˜¯å¦å­˜åœ¨
    if os.path.exists('optimization_gpu.py'):
        print("âœ… æ‰¾åˆ°GPUä¼˜åŒ–è„šæœ¬: optimization_gpu.py")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°optimization_gpu.pyï¼Œè¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨")
    
    # åˆ›å»ºè¿è¡Œè„šæœ¬
    run_script = '''
#!/usr/bin/env python3
# äº‘ç«¯GPUä¼˜åŒ–ç®—æ³•è¿è¡Œè„šæœ¬

import os
import sys
import time

print("ğŸš€ å¯åŠ¨GPUåŠ é€Ÿä¼˜åŒ–ç®—æ³•...")
print(f"Pythonç‰ˆæœ¬: {sys.version}")
print(f"å·¥ä½œç›®å½•: {os.getcwd()}")

# æ£€æŸ¥GPUçŠ¶æ€
os.system("nvidia-smi")

print("\n" + "="*50)
print("å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç®—æ³•")
print("="*50)

start_time = time.time()

# è¿è¡Œä¼˜åŒ–ç®—æ³•
if os.path.exists('optimization_gpu.py'):
    os.system(f"{sys.executable} optimization_gpu.py")
else:
    print("âŒ æœªæ‰¾åˆ°optimization_gpu.pyæ–‡ä»¶")
    sys.exit(1)

end_time = time.time()
print(f"\næ€»è¿è¡Œæ—¶é—´: {end_time - start_time:.2f} ç§’")
'''
    
    with open('run_optimization.py', 'w', encoding='utf-8') as f:
        f.write(run_script)
    
    print("âœ… åˆ›å»ºè¿è¡Œè„šæœ¬: run_optimization.py")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    env_vars = {
        'CUDA_VISIBLE_DEVICES': '0',  # ä½¿ç”¨ç¬¬ä¸€ä¸ªGPU
        'CUPY_CACHE_DIR': '/tmp/cupy_cache',  # è®¾ç½®CuPyç¼“å­˜ç›®å½•
    }
    
    for key, value in env_vars.items():
        os.environ[key] = value
        print(f"è®¾ç½®ç¯å¢ƒå˜é‡: {key}={value}")

def print_usage_instructions():
    """æ‰“å°ä½¿ç”¨è¯´æ˜"""
    print("\n" + "="*60)
    print("ğŸ¯ äº‘ç«¯GPUç¯å¢ƒé…ç½®å®Œæˆ")
    print("="*60)
    
    print("\nğŸ“‹ ä½¿ç”¨è¯´æ˜:")
    print("1. è¿è¡Œä¼˜åŒ–ç®—æ³•:")
    print("   python run_optimization.py")
    print("   æˆ–")
    print("   python optimization_gpu.py")
    
    print("\n2. ç›‘æ§GPUä½¿ç”¨æƒ…å†µ:")
    print("   watch -n 1 nvidia-smi")
    
    print("\n3. æ£€æŸ¥GPUçŠ¶æ€:")
    print("   nvidia-smi")
    
    print("\n4. å¦‚æœé‡åˆ°å†…å­˜ä¸è¶³:")
    print("   - å‡å°‘ç§ç¾¤å¤§å° (population_size)")
    print("   - å‡å°‘é‡‡æ ·ç‚¹æ•°é‡")
    print("   - ä½¿ç”¨æ›´å°çš„æ—¶é—´æ­¥é•¿")
    
    print("\nâš ï¸ æ³¨æ„äº‹é¡¹:")
    print("- ç¡®ä¿é€‰æ‹©äº†GPUå®ä¾‹ç±»å‹")
    print("- é•¿æ—¶é—´è¿è¡Œå¯èƒ½äº§ç”Ÿè´¹ç”¨")
    print("- å»ºè®®å®šæœŸä¿å­˜ä¸­é—´ç»“æœ")
    print("- å¯ä»¥ä½¿ç”¨Ctrl+Cä¸­æ–­è¿è¡Œ")
    
    print("\nğŸ”— ç›¸å…³æ–‡ä»¶:")
    print("- optimization_gpu.py: GPUåŠ é€Ÿä¼˜åŒ–ç®—æ³•")
    print("- run_optimization.py: å¿«é€Ÿè¿è¡Œè„šæœ¬")
    print("- install_gpu_deps.py: ä¾èµ–å®‰è£…è„šæœ¬")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ äº‘ç«¯GPUç¯å¢ƒå¿«é€Ÿé…ç½®è„šæœ¬")
    print("=" * 50)
    
    start_time = time.time()
    
    # æ­¥éª¤1: æ£€æŸ¥GPUç¯å¢ƒ
    if not check_gpu_environment():
        print("\nâŒ GPUç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ä¾‹é…ç½®")
        return
    
    # æ­¥éª¤2: å®‰è£…ä¾èµ–
    install_dependencies()
    
    # æ­¥éª¤3: å®‰è£…CuPy
    if not install_cupy():
        print("\nâŒ CuPyå®‰è£…å¤±è´¥ï¼Œå°†æ— æ³•ä½¿ç”¨GPUåŠ é€Ÿ")
        return
    
    # æ­¥éª¤4: æµ‹è¯•GPUæ€§èƒ½
    test_gpu_performance()
    
    # æ­¥éª¤5: é…ç½®ç¯å¢ƒ
    setup_optimization_environment()
    
    # æ­¥éª¤6: æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
    print_usage_instructions()
    
    end_time = time.time()
    print(f"\nâ±ï¸ é…ç½®å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.1f} ç§’")
    print("\nğŸš€ ç°åœ¨å¯ä»¥è¿è¡Œ: python run_optimization.py")

if __name__ == "__main__":
    main()